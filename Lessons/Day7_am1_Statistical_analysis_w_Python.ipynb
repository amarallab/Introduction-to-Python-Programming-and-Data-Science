{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import choice, sample, shuffle\n",
    "import scipy.stats as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_frame(sub, xaxis_label, yaxis_label, font_size = 15, padding = -0.02):\n",
    "    \"\"\"Formats frame, axes, and ticks for matplotlib made graphic with half frame.\"\"\"\n",
    "\n",
    "    # Format graph frame and tick marks\n",
    "    sub.yaxis.set_ticks_position('left')\n",
    "    sub.xaxis.set_ticks_position('bottom')\n",
    "    sub.tick_params(axis = 'both', which = 'major', length = 7, width = 2, direction = 'out', pad = 10,\n",
    "                    labelsize = font_size)\n",
    "    sub.tick_params(axis = 'both', which = 'minor', length = 5, width = 2, direction = 'out', labelsize = 10)\n",
    "    for axis in ['bottom','left']:\n",
    "        sub.spines[axis].set_linewidth(2)\n",
    "        sub.spines[axis].set_position((\"axes\", padding))\n",
    "    for axis in ['top','right']:\n",
    "        sub.spines[axis].set_visible(False)\n",
    "\n",
    "    # Format axes\n",
    "    sub.set_xlabel(xaxis_label, fontsize = 1.6 * font_size)\n",
    "    sub.set_ylabel(yaxis_label, fontsize = 1.6 * font_size)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this unit we will:\n",
    "\n",
    "* Define descriptive and inferential statistics\n",
    "* Demonstrate decriptive and inferential statistics in Python\n",
    "* Cover basic bootstrapping methods for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "**Statistics is the science concerned with the study of the collection, analysis, interpretation, presentation, and organization of data.**\n",
    "\n",
    "For concreteness let us consider two examples that hopefully you can relate to.\n",
    "\n",
    "The US Census Bureau collects data on people residing in the US. The data includes measures such as the number of household occupants, their gender, their age, their familial relationships, their incomes, their education levels, and so on. The process for the data collection is called a **census** because the process aims to measure all individuals.\n",
    "\n",
    "Colleges collect applications for their programs. The data collected includes standardized test scores, GPAs, essays, recommendation letters, and so on. No college is able to collect a census, so each must make decisions based on the **sample** of applicants. Each college is able to analyze a sample comprising a very small fraction of all students applying to college each year.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn more about these situations, let us consider the data we obtained when analyzing the sentiment score of the lines of Othelo and Iago.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Day7-Structured-Data-Analysis//iago.json', 'r') as file1:\n",
    "    iago_sentiment = json.load(file1)\n",
    "    \n",
    "\n",
    "with open('../Data/Day7-Structured-Data-Analysis/othello.json', 'r') as file1:\n",
    "    othello_sentiment = json.load(file1)\n",
    "    \n",
    "N_othello = len(othello_sentiment)\n",
    "N_iago = len(iago_sentiment)\n",
    "\n",
    "print(\"Othello's data has {0} data points. \\nIago's data has {1} data points.\\n\".format(N_othello, N_iago) )\n",
    "\n",
    "print(iago_sentiment[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "The first step in the analysis of data is to to obtain a description that summarizes its statistical properties. There are a number of statistics (that is, measures that can be calculated for that data) that are particularly useful.\n",
    "\n",
    "**Number of observations** is the number of data in the data set. In this case, the number of applicants for which we have GPA values.\n",
    "\n",
    "**Minimum** is the smallest value in the data set.\n",
    "\n",
    "**Maximum** is the largest value in the data set. For the GPA data, this is presumably 4.0.\n",
    "\n",
    "**Support** (also called range) is the interval over which the values of the data set spread. Since GAPs are positive and must be no larger that 4, we know that the range must be a subset of the interval [0, 4]. Presumably, students will GPAs lower than 2 will not apply to a graduate program, so the support of our GPA data will likely be a subset of the interval [2, 4].\n",
    "\n",
    "**Mode** is the most common value in the data set.  \n",
    "\n",
    "**Median** is the value that is larger than half of all values and smaller than half of all values in the data set. The median is an example of a *percentile*.  Two other common percentiles are the *first quartile* and the *third quartile*.\n",
    "\n",
    "**Sample Mean** (also called sample average) is the sum of all values divided by the number of observations.  The sample mean has the smallest distance to the set of all values in the sample.\n",
    "\n",
    "**Standard deviation** is a measure of the spread around the sample mean for the values in the data set.\n",
    "\n",
    "**Skewness** is a measure of the asymmetry of the values in the data set. If you divide the support of the data at the sample mean, and if one of the interval is longer than the other, than the data is skewed.\n",
    "\n",
    "These quantities can all be easily obtained used methods already coded in `Scipy` and `Numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.stats as stat\n",
    "#import numpy as np\n",
    "\n",
    "mode = float(stat.mode(othello_sentiment)[0])\n",
    "print(\"The mode of the sample is {0:4.2f}\".format(mode))\n",
    "\n",
    "first_quartile = stat.scoreatpercentile(othello_sentiment, 25)\n",
    "print(\"The first quartile of the sample is {0:4.2f}\".format(first_quartile))\n",
    "\n",
    "median = stat.scoreatpercentile(othello_sentiment, 50)\n",
    "print(\"The median of the sample is {0:4.2f}\".format(median))\n",
    "\n",
    "third_quartile = stat.scoreatpercentile(othello_sentiment, 75)\n",
    "print(\"The third quartile of the sample is {0:4.2f}\".format(third_quartile))\n",
    "\n",
    "skew = stat.skew(othello_sentiment)\n",
    "print(\"The skewness of the sample is {0:5.3f}\".format(skew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stat.describe(othello_sentiment)\n",
    "print(results)\n",
    "\n",
    "print()\n",
    "\n",
    "results = stat.describe(iago_sentiment)\n",
    "print(results)\n",
    "\n",
    "# Let's prettify these results so that they are easier to read by humans\n",
    "# You code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the distribution\n",
    "\n",
    "While descriptive statistics are very useful, their calculation involves the loss of a lot of information on the data.  Obtaining an histogram of the data values gives a much more accurate picture of the statistical properties of the data *as long as the histogram is calculated properly*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (8, 9) )\n",
    "my_font_size = 15\n",
    "\n",
    "sub1 = fig.add_subplot(2,1,1)\n",
    "sub2 = fig.add_subplot(2,1,2)\n",
    "\n",
    "half_frame(sub1, \"\", \"Probability mass\", font_size = my_font_size)\n",
    "half_frame(sub2, \"Sentiment score\", \"Cumulative probability\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram\n",
    "#\n",
    "sub1.hist([othello_sentiment, iago_sentiment], 9, normed = 1, color = ['r', 'darkblue'], rwidth = 0.75, alpha = 0.5, \n",
    "          histtype = \"bar\", label = ['Othello', 'Iago'], cumulative = False)\n",
    "\n",
    "sub2.hist([othello_sentiment, iago_sentiment], 9, normed = 1, color = ['r', 'darkblue'], rwidth = 0.75, alpha = 0.5, \n",
    "          histtype = \"bar\", label = ['Othello', 'Iago'], cumulative = True)\n",
    "\n",
    "# Format legend\n",
    "sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What question we may want to answer with our data is whether Othello and Iago express similar levels of sentiment in their speeches.  Looking at the probability mass function, one could be tempted to say maybe... The cumulative probability plot, however, suggest that probably not.  How do we decide?  \n",
    "\n",
    "\n",
    "## Inferential statistics\n",
    "\n",
    "The goal of descriptive statistics is to gain sufficient insight into our data to enable us to develop hypotheses about what process generated the data or whether different samples were drawn from the same distribution. **These hypotheses are called null models**.\n",
    "\n",
    "The process can be a physical model, which may or may not predict the value of the parameters necessary to describe the statistical properties of the data. The process can also be a statistical model.\n",
    "\n",
    "Using inferential statistics, one determines whether a given null hypothesis is consistent with the data. Let's test the null hypothesis using a few standard methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using t-test\n",
    "\n",
    "t, p = stat.ttest_ind(othello_sentiment, iago_sentiment, equal_var = False)\n",
    "print('t test: \\t t =  {0:6.4f}  \\t p = {1:6.4f}'.format(t, p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kolmogorov-Smirnov test\n",
    "\n",
    "D, p = stat.ks_2samp(othello_sentiment, iago_sentiment)\n",
    "print('KS 2 sample test: \\t  D =  {0:6.4f}  \\t p = {1:6.4f}'.format(D, p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using chi_square test\n",
    "# http://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/chi2samp.htm\n",
    "\n",
    "hist_othello, edges = np.histogram(othello_sentiment, bins = 9, density = False)\n",
    "hist_iago, edges = np.histogram(iago_sentiment, bins = 9, density = False)\n",
    "print(hist_othello)\n",
    "print(hist_iago)\n",
    "\n",
    "# Calculate chisquared statistic\n",
    "chisquared = 0\n",
    "factor1 = math.sqrt(N_iago/N_othello)\n",
    "factor2 = math.sqrt(N_othello/N_iago)\n",
    "for i in range(len(hist_othello)):\n",
    "    if hist_othello[i] != 0:\n",
    "        chisquared += (factor1 * hist_othello[i] - factor2 * hist_iago[i])**2 / ((hist_othello[i] + hist_iago[i]))\n",
    "\n",
    "p = stat.distributions.chi2.sf(chisquared, len(hist_othello))\n",
    "print('chi^2 goodness of fit test: \\t chi^2 =  {0:6.4f}  \\t p = {1}'.format(chisquared, p) )\n",
    "chisquared_data = chisquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok!  So all three tests suggest that the differences are not significant. Should we trust these results, though?\n",
    "\n",
    "If we think about it, the `t-test` and the `KS` are **clearly** not good tests for these data. The data is bimodal (there goes the `t-test`) and discrete/categorical  (there goes the `KS test`).  What about the $\\chi^2$ test? How do we know whether its assumptions are fullfilled?\n",
    "\n",
    "The $\\chi^2$ test requires three conditions to be satisfied: 1) the data is obtained by simple random sampling, 2) the data is categorical, and 3) the expected number of observations for every category is at least 5.\n",
    "\n",
    "Conditions 2 and 3 are clearly fullfilled. Condition 1 is a little trickier. We are not really doing any sampling. We are getting all the data that there is to get except for the possibility that the play was altered during or after its creation and that the removed parts were select in a biased manner... \n",
    "\n",
    "What do we do in case it is really difficult to figure out whether the conditions of a test are fullfilled?\n",
    "\n",
    "# Bootstrap methods\n",
    "\n",
    "That is where bootstrapping approaches can help!!\n",
    "\n",
    "We want to test the null hypothesis that the two samples are drawn from the same distribution.  Well, if both samples are drawn from the same distribution, we can put all the data together into a single sample.  And then we can use that combined sample, to generate pretty much an unlimited number of synthetic samples with the same sizes as our data.\n",
    "\n",
    "Let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combined data set\n",
    "\n",
    "joint_sample = copy(othello_sentiment)\n",
    "joint_sample.extend(iago_sentiment)\n",
    "print(len(joint_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data sets\n",
    "\n",
    "othello_synthetic = sample(joint_sample, N_othello)\n",
    "iago_synthetic = sample(joint_sample, N_iago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use t-test to check differences in average\n",
    "\n",
    "t, p = stat.ttest_ind(othello_sentiment, iago_sentiment, equal_var = False)\n",
    "print('ttest_ind - data: \\t t =  {0:6.4f}'.format(t) )\n",
    "\n",
    "t, p = stat.ttest_ind(othello_synthetic, iago_synthetic, equal_var = False)\n",
    "print('ttest_ind - synthetic: \\t t =  {0:6.4f}'.format(t) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to perform these analyses repeatedly\n",
    "\n",
    "N_replicates = 5\n",
    "t_statistic = []\n",
    "D_statistic = []\n",
    "chisquared_statistic = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, we have our results, we can plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize = (8, 15) )\n",
    "my_font_size = 15\n",
    "\n",
    "sub1 = fig.add_subplot(3,1,1)\n",
    "sub2 = fig.add_subplot(3,1,2)\n",
    "sub3 = fig.add_subplot(3,1,3)\n",
    "\n",
    "half_frame(sub1, \"t statistic\", \"Probability density\", font_size = my_font_size)\n",
    "half_frame(sub2, \"D statistic\", \"Probability density\", font_size = my_font_size)\n",
    "half_frame(sub3, \"chi^2 statistic\", \"Probability density\", font_size = my_font_size)\n",
    "\n",
    "# Calculate and plot histogram\n",
    "#\n",
    "sub1.hist(t_statistic, 30, normed = 1, color = 'darkblue', rwidth = 0.75, alpha = 0.5, \n",
    "          histtype = \"bar\", cumulative = True)\n",
    "\n",
    "t, p = stat.ttest_ind(othello_sentiment, iago_sentiment, equal_var = False)\n",
    "sub1.vlines(t, ymin = 0, ymax = 0.99, lw = 3, color = \"red\", label = \"data\")\n",
    "\n",
    "sub2.hist(D_statistic, 30, normed = 1, color = 'darkblue', rwidth = 0.75, alpha = 0.5, \n",
    "          histtype = \"bar\", cumulative = True)\n",
    "\n",
    "D, p = stat.ks_2samp(othello_sentiment, iago_sentiment)\n",
    "sub2.vlines(D, ymin = 0, ymax = 1, lw = 3, color = \"red\", label = \"data\")\n",
    "\n",
    "\n",
    "sub3.hist(chisquared_statistic, 200, normed = 1, color = 'darkblue', rwidth = 0.75, alpha = 0.5, \n",
    "          histtype = \"bar\", cumulative = True)\n",
    "\n",
    "sub3.vlines(chisquared_data, ymin = 0, ymax = 1, lw = 3, color = \"red\", label = \"data\")\n",
    "sub3.set_xlim([0,20])\n",
    "\n",
    "# Format legend\n",
    "#sub1.legend(loc = \"best\", frameon = False, markerscale = 1.8, fontsize = my_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the differences between the sentiment levels of Iago's and Othello's speech are not statistically significant.  It would be interesting to compare their speeches with those uttered by characters from other plays..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
