{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../Data/www/styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "In this unit we will discuss how to randomly generate possible data sets from a set of sample data (known as bootstrapping). To do that we will cover:\n",
    "\n",
    "* Why/when you would need to bootstrap data\n",
    "* How to bootstrap data\n",
    "* How to statistically evaluate bootstrapped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap methods\n",
    "\n",
    "When doing science, ideally, one would have many replicates of an experiment.  The replicates would enable us to calculate both an expected outcome and the variability in outcomes.  Those quantities would then enable us, under certain assumptions, to estimate the chance that some observed difference from a null model could be explained by chance or not.\n",
    "\n",
    "But what can we do when we only have one replicate?  This is frequently the case with observational studies, but it can occur in other contexts too.\n",
    "\n",
    "However, there are other areas where Bootstrapping Monte Carlo chains is a useful computational approach.\n",
    "\n",
    "One area, that you might not have though of, is estimating a value.\n",
    "\n",
    "A classic example is trying to calculate what is the value of $pi$. $pi$ isn't an actual numerical number, it's the ratio of a circle's circumference to its diameter.\n",
    "\n",
    "While your calculator now knows what that approximation is a number---how would you calculate it?\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Well one way is to numerically approximate it using a bootstrap.\n",
    "\n",
    "The procedure is actually pretty simple. All we would do is randomly select points in the unit-square and then check to see if it's inside the circle or not.\n",
    "\n",
    "Our overall estimate of the value of $pi$ would then just be the number of points successfully within the circle divided by the number of points we randomly picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853981633974483\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Calculate pi by calculating area of quarter circle\n",
    "\n",
    "def estimate_pi(n_attempts = 10000):\n",
    "    \"\"\" Estimate pi from area of quarter circle \"\"\" \n",
    "    count_successes = 0\n",
    "    for i in range(n_attempts):\n",
    "        x_rand = np.random.random()\n",
    "        y_rand = np.random.random()\n",
    "        dist = math.sqrt( x_rand **2 + y_rand**2 )\n",
    "        if dist <= 1.:\n",
    "            count_successes += 1\n",
    "    return float(count_successes) / n_attempts\n",
    "\n",
    "\n",
    "print( math.pi / 4. )\n",
    "print( estimate_pi(10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you'll see, is that our estimate of $pi$ gets increasingly better the more points that we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7853981633974483\n",
      "0.786\n"
     ]
    }
   ],
   "source": [
    "print( math.pi / 4. )\n",
    "print( estimate_pi(100000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with enough random points our answer will converge to the exact answer that the computer already returns.\n",
    "\n",
    "This may seem like a pretty simple example (because you were taught what the value of $pi$ is), but this is actually a very real problem --- a lot of the time we don't know what the value of some distribution is and we **don't** know an equation to calculate it so we need to numerically approximate it using a Monte Carlo Bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this method to easily estimate probabilities --- like what is the probability that the sum of the dots on two die will equal a certain value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.06\n",
      "0.056\n",
      "0.055098\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prob_of_outcome_tossing_n_dice(sum_dots, n, n_attempts = 1000):\n",
    "    \"\"\" Probability of the sum of the dots in n dice being sum_dots\"\"\"\n",
    "    count_successes = 0\n",
    "    for a in range(n_attempts):\n",
    "        # Toss dice\n",
    "        sum_temp = 0\n",
    "        for i in range(n):\n",
    "            sum_temp += np.random.randint(6) + 1\n",
    "        if sum_temp == sum_dots:\n",
    "            count_successes += 1\n",
    "    \n",
    "    return float(count_successes) / n_attempts\n",
    "\n",
    "print( prob_of_outcome_tossing_n_dice(3, 2, 10) )\n",
    "print( prob_of_outcome_tossing_n_dice(3, 2, 100) )\n",
    "print( prob_of_outcome_tossing_n_dice(3, 2) )\n",
    "print( prob_of_outcome_tossing_n_dice(3, 2, 1000000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping data\n",
    "\n",
    "Back when we first analyzed text, I asked the question of whether the play 'Othello' should have been named 'Iago'. That question came from the fact, that at a rudimentary analysis, Iago seems to be the main speaker from a data analysis perspective. \n",
    "\n",
    "However, in the exercises we switched to a more complex metric, the entropy, evaluate who was the more articulate speaker (with our idea being that the more articulate speaker may be the main character). When we calculated the entropy Iago had a slightly higher measure than Othello's. The problem is we didn't know how to answer if the **difference was significant**.\n",
    "\n",
    "This is a common situation - you use all of your available data points to calculate a single metric that encodes some measure or performance of the data. However, this leaves you with only one number for each category (which is essentially just **one observation**) --- there's no way that you can run a t-test with just one observation (at least I hope you would never try)!\n",
    "\n",
    "What do you do?\n",
    "\n",
    "## The bootstrap -- or creating ensembles of data\n",
    "\n",
    "The answer is to bootstrap your data. What this means seems complicated but it actually is very simple, the procedure is as follows:\n",
    "\n",
    "1. Randomly select individual data points from our source data to create a new synthetic dataset\n",
    "2. Calculate our metric of interest on the synthetic dataset\n",
    "3. Repeat steps 1-2 $10^3$ - $10^6$ times (depending on data/metric)\n",
    "4. Evaluate the distribution of synthetic results to the real value from the data\n",
    "\n",
    "Put simply, we create lots of *possible* datasets from our observed data and see how our value compares to the *possible* data (or how one set of *possible* data compares to another set of *possible* data).\n",
    "\n",
    "There are only two ways to sample data to generate synthetic datasets -- **with or without** replacement. \n",
    "\n",
    "* **with replacement** when we select a data point to put in our synthetic dataset, we leave it in the original dataset so it could be drawn again\n",
    "* **without replacement** when we select a data point to put in our synthetic dataset, we remove it from the original dataset so it cannot be drawn again\n",
    "\n",
    "## What's the difference between these two methods?\n",
    "\n",
    "Well, it's somewhat hard to give a definition that is both concrete/understandable and general --- but as a guideline:\n",
    "\n",
    "If you are interested in calculating the difference between two metrics or an observed value against a probable process, you are most likely interested in sampling **with replacement**. To do this you typically keep the synthetic dataset size **fixed** and **equal to the original number of observations**. If you sampled without replacement then you would generate synthetic datasets that are identical to each other and the original dataset.\n",
    "\n",
    "If you are interested in calculating the relationship between datapoints in time (i.e. one value following another in time), you are more likely intersted in sampling **without replacement**. You're interested not in observing different values, which 'with replacement' would give, but instead if there is a difference in how one data point follows another in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The entropy of Othello and Iago\n",
    "\n",
    "To make this concrete, let's recap the entropy of Othello and Iago's dialogue. \n",
    "\n",
    "First we have to read in the dialogue and calculate the entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_othello_play():\n",
    "    '''\n",
    "    Extracts the othello play from the Shakespeare.txt file\n",
    "    '''\n",
    "    complete_works = open('../Data/Day5-Text-Analysis/Shakespeare.txt').read()\n",
    "    #Cut off the beginning plays\n",
    "    othello_full = complete_works.split('OTHELLO, MOOR OF VENICE\\n\\nby William Shakespeare\\n\\n\\n\\n')[1]\n",
    "    #Cut off the plays after\n",
    "    othello_text = othello_full.split('\\n\\n\\nTHE END')[0]\n",
    "    #Clean out the electronic message\n",
    "    emessage = '''<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\\nPERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\\nCOMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\\nSERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>'''\n",
    "    emessage_split = othello_text.split(emessage)\n",
    "    #Preamble is the first part\n",
    "    othello_preamble = emessage_split[0]\n",
    "    #Text is the other part\n",
    "    othello_clean_text = ''.join(emessage_split[1:])\n",
    "    othello_lines = othello_clean_text.split('\\n')\n",
    "    return othello_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punctuation(word):\n",
    "    punc = ',.:;\"\\'?![]{}-'\n",
    "    return word.lstrip(punc).strip(punc).lower()\n",
    "\n",
    "def find_character_dialogue(character_name, text):\n",
    "    '''\n",
    "    Finds all dialogue lines for a given character name\n",
    "    input:\n",
    "        character_name: name of character, all caps including period. \n",
    "        text: text to find character name in\n",
    "    output:\n",
    "        dialogue: list of words character uses\n",
    "    '''\n",
    "    dialogue = []\n",
    "\n",
    "    #I create a variable to track if othello was the last character speaking\n",
    "    preceding_character = False\n",
    "    for line in text:\n",
    "        #First check is if we are in a correct character block of dialogue or not\n",
    "        if preceding_character == True:\n",
    "            #Check to make sure that another character isn't speaking\n",
    "            #Continued text starts with four spaces\n",
    "            if '    ' == line[:4]:\n",
    "                dialogue += [w for w in line.split(' ') if w != '' and w != ' ']\n",
    "            else:\n",
    "                #Character isn't speaking, flip the preceding_othello flag\n",
    "                preceding_character = False\n",
    "        else:\n",
    "            #lets check to see if character is speaking\n",
    "            if character_name in line:\n",
    "                #append the line to othellos dialogue\n",
    "                dialogue += [w for w in line.split(character_name)[1].split(' ') if w != '' and w != ' ']\n",
    "                #Switch our preceding check to true\n",
    "                preceding_character = True\n",
    "            else:\n",
    "                #I am explicitly accounting for the character not speaking, but not using this for anything\n",
    "                pass\n",
    "    return dialogue\n",
    "\n",
    "othellos_dialogue = [strip_punctuation(w) for w in find_character_dialogue('OTHELLO.', extract_othello_play())]\n",
    "iagos_dialogue = [strip_punctuation(w) for w in find_character_dialogue('IAGO.', extract_othello_play())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Othello  6.126593244621015\n",
      "Iago  6.139003713381113\n"
     ]
    }
   ],
   "source": [
    "def calc_entropy(words):\n",
    "    '''\n",
    "    input:\n",
    "        words: list of all words uttered\n",
    "    output:\n",
    "        entropy: float\n",
    "    '''\n",
    "    total_words = len(words)\n",
    "    counted_words = Counter(words)  \n",
    "    #Start the calculation\n",
    "    entropy = 0\n",
    "    for word, value in counted_words.items():\n",
    "        entropy += value/total_words * np.log(value/total_words)\n",
    "    return -1 * entropy\n",
    "\n",
    "print('Othello ', calc_entropy(othellos_dialogue))\n",
    "print('Iago ', calc_entropy(iagos_dialogue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So now the question is....are these different?\n",
    "\n",
    "Well, to be facetious we can run a t-test on the two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adampah/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/Users/adampah/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=nan, pvalue=nan)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "othello_entropy = calc_entropy(othellos_dialogue)\n",
    "iago_entropy = calc_entropy(iagos_dialogue)\n",
    "\n",
    "stats.ttest_ind([othello_entropy], [iago_entropy] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, doesn't work because we only have one value! So we need to bootstrap, so how can we set this problem up?\n",
    "\n",
    "Well, let's break this down further.\n",
    "\n",
    "We have two individual metrics that summarize a dataset and we want to know if they significantly differ.\n",
    "\n",
    "To bootstrap, we really need to calculate if one observed value is different than a synthetic distribution of data. Anything more and it becomes hard to really interpret the comparisons.\n",
    "\n",
    "So what's the answer to make this doable? \n",
    "\n",
    "Well we can actually bootstrap the **difference** in entropy between Othello's and Iago's dialogue! That's a single metric that we can easily compare.\n",
    "\n",
    "So what do we care about? \n",
    "\n",
    "Well the dialogue size of both Iago and Othello should be fixed to account for that difference. This suggests that we should sample each individual's dialogue with replacement from their original dialogue. Then we record the difference between the two synthetic dialogues.\n",
    "\n",
    "If the the real difference is significantly larger than the synthetically generated dialogues' differences then we would conclude that the entropy of one character is significantly different than random language usage.\n",
    "\n",
    "So how do we do this? Well first we should write a function to generate synthetic dialogue for a single character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6284\n",
      "['i', 'my', 'it', 'cassio', 'thy', 'it', 'wanting', 'what', \"think'st\", 'o']\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dialogue_generator(dialogue):\n",
    "    import random\n",
    "    new_dialogue = []\n",
    "    for i in range(len(dialogue)):\n",
    "        new_dialogue.append( random.choice(dialogue) )\n",
    "    return new_dialogue\n",
    "\n",
    "synthetic_dialogue = synthetic_dialogue_generator(othellos_dialogue)\n",
    "print( len(synthetic_dialogue) )\n",
    "print(synthetic_dialogue[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should write a function that generates synthetic dialogues for each character and calculates the difference in entropy. This function should generate 1000 synthetic dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_entropies_difference(dialogue1, dialogue2, n=1000):\n",
    "    synthetic_entropies = []\n",
    "    for i in range(n):\n",
    "        ent1 = calc_entropy( synthetic_dialogue_generator(dialogue1) )\n",
    "        ent2 = calc_entropy( synthetic_dialogue_generator(dialogue2) )\n",
    "        synthetic_entropies.append(ent1 - ent2)\n",
    "    return synthetic_entropies\n",
    "\n",
    "synth_diffs = generate_synthetic_entropies_difference(othellos_dialogue, iagos_dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we can see that the difference in entropy of the dialogue between the two characters is not distinct.\n",
    "\n",
    "If we had approached this problem in a different manner, say looking at a single individual's dialogue and comparing it to the synthetic distribution it would have been much more complicated. \n",
    "\n",
    "Framing the problem is one of the most important parts of properly bootstrapping data to understand significance! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
